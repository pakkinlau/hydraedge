{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1b6e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (minimal role + lookup tables)\n",
    "\n",
    "from pathlib import Path\n",
    "import json, hashlib, numpy as np, spacy, torch\n",
    "from transformers import AutoModelForTokenClassification, AutoTokenizer\n",
    "import srl  # from liaad wrapper\n",
    "\n",
    "# ─── deterministic seed everywhere ────────────────────────────────────────────\n",
    "SEED = 42\n",
    "np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "\n",
    "# ─── constants & helper artefacts (tiny demo versions) ───────────────────────\n",
    "ROLES         = [\"Predicate\", \"Subject\", \"Object\", \"IndirectObject\", \"Attr\", \"Tense\",\n",
    "                 \"VerbClass\", \"Type\", \"Source\", \"Date\", \"Venue\", \"CHV\"]\n",
    "ROLE_VECTORS  = {r: np.random.choice([-1, 1], 4096).astype(np.int8) for r in ROLES}\n",
    "\n",
    "JL_MATRIX     = np.random.randn(4096, 768).astype(np.float32) / np.sqrt(768)  # throw-away demo\n",
    "RESOLVE_DICT  = {\"i\": \"i\", \"white\": \"white\", \"dog\": \"dog\", \"chase\": \"chase\",\n",
    "                 \"cat\": \"cat\", \"quickly\": \"quickly\", \"backyard\": \"backyard\"}\n",
    "\n",
    "def jl_project(vec_768: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Dense → 4096, sign-binarised.\"\"\"\n",
    "    return np.sign(JL_MATRIX @ vec_768).astype(np.int8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750dccb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (load spaCy + SRL once)\n",
    "\n",
    "# spaCy transformer (only tokenizer / POS / DEP)\n",
    "nlp = spacy.load(\"en_core_web_trf\", exclude=[\"ner\"])\n",
    "nlp.max_length = 512\n",
    "\n",
    "# SRL pipeline (english)\n",
    "srl_tokenizer = AutoTokenizer.from_pretrained(\"liaad/srl-en_xlmr-large\")\n",
    "srl_model     = AutoModelForTokenClassification.from_pretrained(\"liaad/srl-en_xlmr-large\")\n",
    "srl_pipe      = srl.SRL_Predictor(model=srl_model, tokenizer=srl_tokenizer, batch=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1246c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (ultra-thin deterministic extractor)\n",
    "\n",
    "def resolve_alias(txt: str) -> str:\n",
    "    key = txt.lower().strip()\n",
    "    return RESOLVE_DICT.get(key, key)          # fallback = lower-cased text\n",
    "\n",
    "def simple_rule_map(frame):\n",
    "    \"\"\"\n",
    "    Maps SRL labels → {Subject, Object, ...}.\n",
    "    Again: minimal demo rules for PropBank labels.\n",
    "    \"\"\"\n",
    "    label = frame[\"tag\"]\n",
    "    if label == \"B-ARG0\":\n",
    "        return \"Subject\"\n",
    "    if label in (\"B-ARG1\", \"B-ARG2\"):\n",
    "        return \"Object\"\n",
    "    if label.startswith(\"B-ARGM-LOC\"):\n",
    "        return \"IndirectObject\"\n",
    "    if label.startswith(\"B-ARGM-MNR\"):\n",
    "        return \"Attr\"\n",
    "    return None  # ignore the rest for the demo\n",
    "\n",
    "def encode_chv(tuples, gamma=0.15):\n",
    "    \"\"\"Implements Eq. (1) in the checklist using majority-vote bundling.\"\"\"\n",
    "    accum = np.zeros(4096, dtype=np.int32)\n",
    "    for role, f_vec in tuples:                     # f_vec already ±1\n",
    "        r_vec = ROLE_VECTORS[role]\n",
    "        bound = r_vec * f_vec\n",
    "        mixed = (1 - gamma) * bound + gamma * f_vec\n",
    "        accum += mixed.astype(np.int32)\n",
    "    return np.sign(accum).astype(np.int8)\n",
    "\n",
    "def extract(sentence: str, meta: dict, doc_id=\"DOC1\", sent_id=\"0001\"):\n",
    "    doc = nlp(sentence)\n",
    "    frames = srl_pipe.predict(sentence)[\"verbs\"]\n",
    "\n",
    "    nodes, edges, tuples_for_chv = [], [], []\n",
    "    eid_counter = 1\n",
    "\n",
    "    for verb_frame in frames:\n",
    "        predicate = verb_frame[\"verb\"]\n",
    "        args      = verb_frame[\"tags\"]\n",
    "        words     = verb_frame[\"words\"]\n",
    "\n",
    "        # create predicate node\n",
    "        pred_id = f\"spo:{predicate}@e{eid_counter}\"\n",
    "        nodes.append({\n",
    "            \"id\": pred_id, \"filler\": predicate, \"alias_key\": resolve_alias(predicate),\n",
    "            \"roles\": [\"Predicate\"], \"eid_set\": [f\"e{eid_counter}\"], \"ntype\": \"spo\",\n",
    "            \"char_start\": sentence.index(predicate), \"char_end\": sentence.index(predicate) + len(predicate)\n",
    "        })\n",
    "\n",
    "        # walk over labelled tokens\n",
    "        current_arg = None\n",
    "        for w, tag in zip(words, args):\n",
    "            role = simple_rule_map({\"tag\": tag})\n",
    "            if role is None:\n",
    "                continue\n",
    "            node_id = f\"spo:{w}@e{eid_counter}\"\n",
    "            if node_id not in {n[\"id\"] for n in nodes}:\n",
    "                nodes.append({\n",
    "                    \"id\": node_id, \"filler\": w, \"alias_key\": resolve_alias(w),\n",
    "                    \"roles\": [role], \"eid_set\": [f\"e{eid_counter}\"], \"ntype\": \"spo\",\n",
    "                    \"char_start\": sentence.index(w), \"char_end\": sentence.index(w) + len(w)\n",
    "                })\n",
    "            # edges\n",
    "            if role == \"Subject\":\n",
    "                edges.append({\"source\": node_id, \"target\": pred_id, \"kind\": \"S-P\"})\n",
    "            elif role == \"Object\":\n",
    "                edges.append({\"source\": pred_id, \"target\": node_id, \"kind\": \"P-O\"})\n",
    "            else:\n",
    "                edges.append({\"source\": node_id, \"target\": pred_id, \"kind\": \"attr\"})\n",
    "\n",
    "            # collect CHV pieces\n",
    "            filler_vec = jl_project(np.random.randn(768))   # placeholder! use real embed\n",
    "            tuples_for_chv.append((role, filler_vec))\n",
    "\n",
    "        eid_counter += 1\n",
    "\n",
    "    # CHV anchor node\n",
    "    nodes.append({\"id\":\"chv:main\",\"filler\":\"CHV\",\"roles\":[\"CHV\"],\"eid_set\":[],\"ntype\":\"chv\"})\n",
    "    payload = {\n",
    "        \"version\":\"2.4-demo\",\n",
    "        \"sentence\": sentence,\n",
    "        \"nodes\": nodes,\n",
    "        \"edges\": edges,\n",
    "        \"layouts\": {\"hulls\":[]}\n",
    "    }\n",
    "    chv = encode_chv(tuples_for_chv)\n",
    "    return payload, chv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617071c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (run the example sentence)\n",
    "\n",
    "test_sent = \"I saw a white dog chase the brown cat quickly in the backyard.\"\n",
    "meta      = {\"date\":\"2025-07-05\",\"source\":\"Book_X\"}\n",
    "payload, chv = extract(test_sent, meta)\n",
    "\n",
    "print(json.dumps(payload, indent=2, ensure_ascii=False)[:1000])  # first 1 kB\n",
    "print(\"CHV shape:\", chv.shape, \"∈ {-1,+1}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
