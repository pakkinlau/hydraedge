{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee03846d",
   "metadata": {},
   "source": [
    "Reference:\n",
    "- https://chatgpt.com/share/6865fe5a-fdac-800e-b719-945403c9d33d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6edc8f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/usr/local/lib/python3.10/dist-packages/fairscale/experimental/nn/offload.py:19: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  return torch.cuda.amp.custom_fwd(orig_func)  # type: ignore\n",
      "/usr/local/lib/python3.10/dist-packages/fairscale/experimental/nn/offload.py:30: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  return torch.cuda.amp.custom_bwd(orig_func)  # type: ignore\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module transformers has no attribute AdamW",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mallennlp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpredictors\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpredictor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Predictor\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# ── deterministic seeds ───────────────────────────────────────\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrandom\u001b[39;00m\u001b[38;5;241m,\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\u001b[38;5;241m,\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/allennlp/predictors/__init__.py:9\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mA `Predictor` is\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03ma wrapper for an AllenNLP `Model`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03ma `Predictor` that wraps it.\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mallennlp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpredictors\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpredictor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Predictor\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mallennlp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpredictors\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msentence_tagger\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SentenceTaggerPredictor\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mallennlp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpredictors\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext_classifier\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TextClassifierPredictor\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/allennlp/predictors/predictor.py:18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mallennlp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DatasetReader, Instance\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mallennlp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Batch\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mallennlp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Model\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mallennlp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marchival\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Archive, load_archive\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mallennlp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m util\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/allennlp/models/__init__.py:8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mallennlp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Model\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mallennlp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marchival\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m archive_model, load_archive, Archive\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mallennlp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbasic_classifier\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BasicClassifier\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mallennlp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmultitask\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MultiTaskModel\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mallennlp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msimple_tagger\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SimpleTagger\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/allennlp/models/basic_classifier.py:12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mallennlp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m InitializerApplicator, util\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mallennlp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_text_field_mask\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mallennlp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CategoricalAccuracy\n\u001b[1;32m     15\u001b[0m \u001b[38;5;129m@Model\u001b[39m\u001b[38;5;241m.\u001b[39mregister(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbasic_classifier\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mBasicClassifier\u001b[39;00m(Model):\n\u001b[1;32m     17\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03m    This `Model` implements a basic text classifier. After embedding the text into\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03m    a text field, we will optionally encode the embeddings with a `Seq2SeqEncoder`. The\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;124;03m        If provided, will be used to initialize the model parameters.\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/allennlp/training/__init__.py:5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mallennlp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TrainerCallback\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mallennlp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Trainer\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mallennlp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgradient_descent_trainer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GradientDescentTrainer\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/allennlp/training/gradient_descent_trainer.py:28\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mallennlp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackward\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MixedPrecisionBackwardCallback\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mallennlp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcheckpointer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Checkpointer\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mallennlp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlearning_rate_schedulers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlearning_rate_scheduler\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LearningRateScheduler\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mallennlp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetric_tracker\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MetricTracker\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mallennlp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmomentum_schedulers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmomentum_scheduler\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MomentumScheduler\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/allennlp/training/learning_rate_schedulers/__init__.py:18\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mAllenNLP uses most\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m`PyTorch learning rate schedulers <https://pytorch.org/docs/master/optim.html#how-to-adjust-learning-rate>`_,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"cosine\", \"noam\", and \"slanted_triangular\", respectively.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mallennlp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlearning_rate_schedulers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlearning_rate_scheduler\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     19\u001b[0m     LearningRateScheduler,\n\u001b[1;32m     20\u001b[0m     ConstantLearningRateScheduler,\n\u001b[1;32m     21\u001b[0m     ConstantWithWarmupLearningRateScheduler,\n\u001b[1;32m     22\u001b[0m     CosineWithWarmupLearningRateScheduler,\n\u001b[1;32m     23\u001b[0m     CosineHardRestartsWithWarmupLearningRateScheduler,\n\u001b[1;32m     24\u001b[0m )\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mallennlp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlearning_rate_schedulers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch_lr_schedulers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     26\u001b[0m     StepLearningRateScheduler,\n\u001b[1;32m     27\u001b[0m     MultiStepLearningRateScheduler,\n\u001b[1;32m     28\u001b[0m     ExponentialLearningRateScheduler,\n\u001b[1;32m     29\u001b[0m     ReduceOnPlateauLearningRateScheduler,\n\u001b[1;32m     30\u001b[0m )\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mallennlp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlearning_rate_schedulers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcombined\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CombinedLearningRateScheduler\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/allennlp/training/learning_rate_schedulers/learning_rate_scheduler.py:7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mallennlp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchecks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ConfigurationError\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mallennlp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregistrable\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Registrable\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mallennlp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Optimizer\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mallennlp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mscheduler\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Scheduler\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimization\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     11\u001b[0m     get_constant_schedule,\n\u001b[1;32m     12\u001b[0m     get_constant_schedule_with_warmup,\n\u001b[1;32m     13\u001b[0m     get_cosine_schedule_with_warmup,\n\u001b[1;32m     14\u001b[0m     get_cosine_with_hard_restarts_schedule_with_warmup,\n\u001b[1;32m     15\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/allennlp/training/optimizers.py:456\u001b[0m\n\u001b[1;32m    435\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    436\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    437\u001b[0m         model_parameters: List[Tuple[\u001b[38;5;28mstr\u001b[39m, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mParameter]],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    443\u001b[0m         amsgrad: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    444\u001b[0m     ):\n\u001b[1;32m    445\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    446\u001b[0m             params\u001b[38;5;241m=\u001b[39mmake_parameter_groups(model_parameters, parameter_groups),\n\u001b[1;32m    447\u001b[0m             lr\u001b[38;5;241m=\u001b[39mlr,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    451\u001b[0m             amsgrad\u001b[38;5;241m=\u001b[39mamsgrad,\n\u001b[1;32m    452\u001b[0m         )\n\u001b[1;32m    455\u001b[0m \u001b[38;5;129m@Optimizer\u001b[39m\u001b[38;5;241m.\u001b[39mregister(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuggingface_adamw\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mHuggingfaceAdamWOptimizer\u001b[39;00m(Optimizer, \u001b[43mtransformers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdamW\u001b[49m):\n\u001b[1;32m    457\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;124;03m    Registered as an `Optimizer` with name \"huggingface_adamw\".\u001b[39;00m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    462\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    463\u001b[0m         model_parameters: List[Tuple[\u001b[38;5;28mstr\u001b[39m, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mParameter]],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    469\u001b[0m         correct_bias: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    470\u001b[0m     ):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py:2175\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2172\u001b[0m             value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(key)\n\u001b[1;32m   2174\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 2175\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2177\u001b[0m \u001b[38;5;28msetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, value)\n\u001b[1;32m   2178\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "\u001b[0;31mAttributeError\u001b[0m: module transformers has no attribute AdamW"
     ]
    }
   ],
   "source": [
    "import json, re, uuid, hashlib\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "import spacy\n",
    "from allennlp.predictors.predictor import Predictor\n",
    "\n",
    "# ── deterministic seeds ───────────────────────────────────────\n",
    "import random, numpy as np, torch\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "\n",
    "# ── load NLP models once ──────────────────────────────────────\n",
    "NLP = spacy.load(\"en_core_web_sm\", disable=[\"ner\", \"textcat\", \"lemmatizer\"])\n",
    "SRL = Predictor.from_path(\n",
    "    \"https://storage.googleapis.com/allennlp-public-models/structured-prediction-srl-bert.2020.12.15.tar.gz\",\n",
    "    cuda_device=-1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785dff69",
   "metadata": {},
   "outputs": [],
   "source": [
    "SENTENCE = \"I saw a white dog chase the brown cat quickly in the backyard.\"\n",
    "print(SENTENCE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd611a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = NLP(SENTENCE)\n",
    "tokens = [t.text for t in doc]\n",
    "deps   = [(t.text, t.dep_, t.head.text, t.i, t.head.i) for t in doc]\n",
    "print(\"Tokens:\", tokens)\n",
    "print(\"Dependency triples (token, dep, head):\")\n",
    "for t,dep,h,_,_ in deps:\n",
    "    print(f\"  {t:>10} ─{dep:<8}→ {h}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0786d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "srl_out = SRL.predict(sentence=SENTENCE)\n",
    "frames  = srl_out[\"verbs\"]           # list of dicts: {verb, tags}\n",
    "print(\"SRL Frames:\")\n",
    "for f in frames:\n",
    "    print(f\"{f['verb']:<6} → {f['description']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550c4efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEP2ROLE = {\n",
    "    \"nsubj\": \"Subject\", \"csubj\": \"Subject\",\n",
    "    \"dobj\": \"Object\", \"obj\": \"Object\",\n",
    "    \"iobj\": \"IndirectObject\",\n",
    "    \"advmod\": \"Attr\", \"amod\": \"Attr\",\n",
    "}\n",
    "SRL2ROLE = {\n",
    "    \"ARG0\": \"Subject\", \"ARG1\": \"Object\", \"ARG2\": \"IndirectObject\",\n",
    "    \"AM-TMP\": \"Time\", \"AM-LOC\": \"IndirectObject\", \"AM-MNR\": \"Attr\",\n",
    "}\n",
    "\n",
    "proto_tuples = []\n",
    "\n",
    "# from dependencies\n",
    "for tok,dep,head,ti,hi in deps:\n",
    "    if dep in DEP2ROLE:\n",
    "        proto_tuples.append({\"role\": DEP2ROLE[dep], \"span\": (ti, ti+1), \"text\": tok})\n",
    "\n",
    "# from SRL\n",
    "for vf in frames:\n",
    "    tags = vf[\"tags\"]\n",
    "    for idx, tag in enumerate(tags):\n",
    "        if tag.startswith(\"B-\"):\n",
    "            role = tag[2:]\n",
    "            end = idx\n",
    "            while end+1 < len(tags) and tags[end+1].startswith(\"I-\"):\n",
    "                end += 1\n",
    "            if role in SRL2ROLE:\n",
    "                span_text = \" \".join(tokens[idx:end+1])\n",
    "                proto_tuples.append({\"role\": SRL2ROLE[role],\n",
    "                                     \"span\": (idx, end+1),\n",
    "                                     \"text\": span_text})\n",
    "\n",
    "print(\"Proto‑tuples:\")\n",
    "for t in proto_tuples:\n",
    "    print(t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b63b573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple heuristic: every finite verb starts a new event.\n",
    "# spaCy POS: FINITE if tag_ in {\"VBD\",\"VBP\",\"VBZ\"} or modal head\n",
    "eids, eid_counter = {}, 0\n",
    "for tok in doc:\n",
    "    if tok.pos_ == \"VERB\" and tok.morph.get(\"VerbForm\") != [\"Inf\"]:\n",
    "        eid_counter += 1\n",
    "        eids[tok.i] = f\"e{eid_counter}\"\n",
    "\n",
    "# propagate eid to SRL verb indices\n",
    "for f in frames:\n",
    "    v_idx = f[\"verb\"].split()[0]  # verb index str e.g. \"saw\"\n",
    "    # locate verb token\n",
    "for t in proto_tuples:\n",
    "    # attach nearest governing verb's eid (fallback e1)\n",
    "    head_i = doc[t[\"span\"][0]].head.i\n",
    "    t[\"eid\"] = eids.get(head_i, \"e1\")\n",
    "\n",
    "print(\"EIDs:\", eids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c321cc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = []\n",
    "node_index = {}            # map filler@eid → id for dedup\n",
    "\n",
    "def slug(text):            # deterministic, lowercase, no punct\n",
    "    return re.sub(r\"[^a-z0-9]+\",\"\",text.lower())[:32] or \"unk\"\n",
    "\n",
    "for tup in proto_tuples:\n",
    "    base = f\"spo:{slug(tup['text'])}@{tup['eid']}\"\n",
    "    if base not in node_index:\n",
    "        n_id = base\n",
    "        node_index[base] = n_id\n",
    "        nodes.append({\n",
    "            \"id\": n_id,\n",
    "            \"filler\": tup[\"text\"],\n",
    "            \"roles\": [tup[\"role\"]],\n",
    "            \"eid_set\": [tup[\"eid\"]],\n",
    "            \"ntype\": \"spo\",\n",
    "        })\n",
    "    else:\n",
    "        # add missing role to existing node\n",
    "        for n in nodes:\n",
    "            if n[\"id\"] == base and tup[\"role\"] not in n[\"roles\"]:\n",
    "                n[\"roles\"].append(tup[\"role\"])\n",
    "\n",
    "# create predicate nodes (explicit)\n",
    "for tok_i,eid in eids.items():\n",
    "    pred = doc[tok_i].lemma_\n",
    "    n_id = f\"spo:{slug(pred)}@{eid}\"\n",
    "    if n_id not in node_index:\n",
    "        node_index[n_id] = n_id\n",
    "        nodes.append({\n",
    "            \"id\": n_id, \"filler\": pred, \"roles\": [\"Predicate\"],\n",
    "            \"eid_set\": [eid], \"ntype\": \"spo\"\n",
    "        })\n",
    "\n",
    "# event stubs\n",
    "for eid in set(eids.values()):\n",
    "    nodes.append({\"id\": f\"evt:{eid}\", \"filler\": eid,\n",
    "                  \"roles\": [\"Event\"], \"eid_set\":[eid], \"ntype\":\"event\"})\n",
    "\n",
    "# single CHV hub\n",
    "nodes.append({\"id\":\"chv:main\",\"filler\":\"CHV\",\"roles\":[\"CHV\"],\n",
    "              \"eid_set\":[],\"ntype\":\"chv\"})\n",
    "\n",
    "print(\"Nodes →\", len(nodes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba2206b",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = []\n",
    "\n",
    "def add_edge(src,tgt,kind):\n",
    "    edges.append({\"source\":src,\"target\":tgt,\"kind\":kind})\n",
    "\n",
    "# S‑P & P‑O\n",
    "for tup in proto_tuples:\n",
    "    if tup[\"role\"] == \"Subject\":\n",
    "        pred_id = f\"spo:{slug(doc[tup['span'][0]].head.lemma_)}@{tup['eid']}\"\n",
    "        add_edge(f\"spo:{slug(tup['text'])}@{tup['eid']}\", pred_id, \"S-P\")\n",
    "    if tup[\"role\"] == \"Object\":\n",
    "        pred_id = f\"spo:{slug(doc[tup['span'][0]].head.lemma_)}@{tup['eid']}\"\n",
    "        add_edge(pred_id, f\"spo:{slug(tup['text'])}@{tup['eid']}\", \"P-O\")\n",
    "\n",
    "# event‑pred\n",
    "for eid in set(eids.values()):\n",
    "    subj_nodes = [n for n in nodes if \"Subject\" in n[\"roles\"] and eid in n[\"eid_set\"]]\n",
    "    if subj_nodes:\n",
    "        add_edge(f\"evt:{eid}\", subj_nodes[0][\"id\"], \"event-pred\")\n",
    "\n",
    "# binder edge (outermost object → CHV)\n",
    "outer_eid = min(set(eids.values()))\n",
    "last_obj = [n[\"id\"] for n in nodes if \"Object\" in n[\"roles\"] and outer_eid in n[\"eid_set\"]][-1]\n",
    "add_edge(last_obj, \"chv:main\", \"binder\")\n",
    "\n",
    "print(\"Edges →\", len(edges))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b81c904",
   "metadata": {},
   "outputs": [],
   "source": [
    "hulls = []\n",
    "for eid in set(eids.values()):\n",
    "    members = [n[\"id\"] for n in nodes if eid in n[\"eid_set\"] and n[\"ntype\"]==\"spo\"]\n",
    "    if members:\n",
    "        hulls.append({\"eid\":eid,\"members\":members})\n",
    "print(\"Hull list:\", hulls)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a25f1c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68d5f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "    \"version\": \"2.1\",\n",
    "    \"sentence\": SENTENCE,\n",
    "    \"nodes\": nodes,\n",
    "    \"edges\": edges,\n",
    "    \"layouts\": {\"hulls\": hulls},\n",
    "}\n",
    "\n",
    "print(json.dumps(payload, indent=2, ensure_ascii=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7297c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>> place JSON‑Schema v2.1 in ./schema.json\n",
    "from jsonschema import Draft202012Validator\n",
    "import yaml, pprint\n",
    "\n",
    "SCHEMA = json.load(open(\"schema.json\"))\n",
    "Draft202012Validator.check_schema(SCHEMA)\n",
    "Draft202012Validator(SCHEMA).validate(payload)\n",
    "print(\"✅  schema‑valid\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
